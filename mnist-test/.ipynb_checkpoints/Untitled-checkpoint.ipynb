{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import library i use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data from mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train /255\n",
    "x_test = x_test /255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  one hard encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=10, input_dim=784, activation='sigmoid'))\n",
    "model.add(Dense(units=10, activation='sigmoid'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 8,070\n",
      "Trainable params: 8,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set loss function and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 2.0937 - acc: 0.3509\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 1.6010 - acc: 0.691 - 4s 66us/step - loss: 1.6003 - acc: 0.6913\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 1.2080 - acc: 0.7680\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.9366 - acc: 0.8108\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.7634 - acc: 0.8423\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.6491 - acc: 0.8631\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.5659 - acc: 0.8750\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.5011 - acc: 0.8841\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.4529 - acc: 0.8916 1s - loss: 0.4\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.4172 - acc: 0.8968\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.3897 - acc: 0.9016\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3681 - acc: 0.9053\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3504 - acc: 0.9080\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.3348 - acc: 0.9108\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.3220 - acc: 0.9137\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.3105 - acc: 0.9167\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.3005 - acc: 0.9185\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2917 - acc: 0.9208\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2842 - acc: 0.9225\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2770 - acc: 0.9238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe844319860>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=adam(lr=0.001), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=200, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model by testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 421us/step\n",
      "\n",
      "test accuracy is: 0.9198\n"
     ]
    }
   ],
   "source": [
    "test_result = model.evaluate(x_test, y_test)\n",
    "print()\n",
    "print('test accuracy is:', test_result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結論: 用adam的話只要三層hiddenlayer+ 20 個 epochs 就可以訓練的不錯XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
